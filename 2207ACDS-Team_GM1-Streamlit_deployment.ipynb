{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Classification Predict Student Solution\n",
    "\n",
    "\n",
    "### Predict Overview: Twitter Sentiment Classification\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received. Your company has been awarded the contract to:\n",
    "\n",
    "- 1. Create a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "- 2. Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n",
    "- 5. evaluate the accuracy of the best machine learning model;\n",
    "- 6. determine what features were most important in the model’s prediction decision, and\n",
    "- 7. explain the inner working of the model to a non-technical audience.\n",
    "\n",
    "Formally the problem statement was given to the data science team, by your manager via email reads as follow:\n",
    "\n",
    "> The collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43,943 tweets were collected. Each tweet is labelled as one of 4 classes, which are described below:\n",
    "\n",
    "> - 2 News: the tweet links to factual news about climate change\n",
    "\n",
    "> - 1 Pro: the tweet supports the belief of man-made climate change\n",
    "\n",
    "> - 0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
    "\n",
    "> - -1 Anti: the tweet does not believe in man-made climate change Variable definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "sns.set()\n",
    "\n",
    "# Libraries for data preparation and model building\n",
    "import string\n",
    "import preprocessor as p\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model importation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "#PARAMETER_CONSTANT = ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('resources/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78139e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>RT @darreljorstad: Funny as hell! Canada deman...</td>\n",
       "      <td>897853122080407553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>All the biggest lies about climate change and ...</td>\n",
       "      <td>925046776553529344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>The Coming Revelation Of The $q$Global Warming...</td>\n",
       "      <td>696354236850786305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>RT @DineshDSouza: Let's see if the world ends ...</td>\n",
       "      <td>846806509732483072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>RT @SteveSGoddard: Obama has no control over t...</td>\n",
       "      <td>628085266293653504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30754</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @TIME: The Pentagon warned that climate cha...</td>\n",
       "      <td>958155326259367937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30755</th>\n",
       "      <td>2</td>\n",
       "      <td>Study finds that global warming exacerbates re...</td>\n",
       "      <td>956048238615900163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30756</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @MikeySlezak: The global green movement pre...</td>\n",
       "      <td>800258621485391872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30757</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ProfEdwardsNZ: NYC Mayor says NY will go f...</td>\n",
       "      <td>871365767895404545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30758</th>\n",
       "      <td>2</td>\n",
       "      <td>RT Sanders: Climate Change Causes Terrorism  h...</td>\n",
       "      <td>666236638155141121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30759 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  \\\n",
       "0             -1  RT @darreljorstad: Funny as hell! Canada deman...   \n",
       "1             -1  All the biggest lies about climate change and ...   \n",
       "2             -1  The Coming Revelation Of The $q$Global Warming...   \n",
       "3             -1  RT @DineshDSouza: Let's see if the world ends ...   \n",
       "4             -1  RT @SteveSGoddard: Obama has no control over t...   \n",
       "...          ...                                                ...   \n",
       "30754          2  RT @TIME: The Pentagon warned that climate cha...   \n",
       "30755          2  Study finds that global warming exacerbates re...   \n",
       "30756          2  RT @MikeySlezak: The global green movement pre...   \n",
       "30757          2  RT @ProfEdwardsNZ: NYC Mayor says NY will go f...   \n",
       "30758          2  RT Sanders: Climate Change Causes Terrorism  h...   \n",
       "\n",
       "                  tweetid  \n",
       "0      897853122080407553  \n",
       "1      925046776553529344  \n",
       "2      696354236850786305  \n",
       "3      846806509732483072  \n",
       "4      628085266293653504  \n",
       "...                   ...  \n",
       "30754  958155326259367937  \n",
       "30755  956048238615900163  \n",
       "30756  800258621485391872  \n",
       "30757  871365767895404545  \n",
       "30758  666236638155141121  \n",
       "\n",
       "[30759 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all columns of the dataframe\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Feature Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "In this section, observations from the EDA will be addressed, futhermore, new features that are necessary for the model will be created.\n",
    "\n",
    "To deal with the data quality issues, tweet-preprocessor library will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f67678a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_train['message']\n",
    "target = df_train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84eea17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP PC\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate CountVectorzer Object\n",
    "vect = TfidfVectorizer(preprocessor=list, tokenizer=list, ngram_range=(1,2), min_df=2, strip_accents='ascii', smooth_idf=False)\n",
    "\n",
    "train_vect = vect.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98f3bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"resources/tfidfvect_team1.pkl\"\n",
    "\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(train_vect,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f5c5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_vect.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8804160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30759, 7343)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = X_train.toarray()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3519fe5",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a7da1",
   "metadata": {},
   "source": [
    "#### Create a Word2Vector object\n",
    "\n",
    "The vectorizer is used to transform a given text into a vector on the basis of the frequency of each word that occurs in the entire text.\n",
    "\n",
    "For this project, CountVectorizer will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c76b756",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b7998c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a LogisticRegression object\n",
    "logreg = LogisticRegression(penalty='l2', C= 0.1, solver='liblinear', multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7904141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "logistic_reg = logreg.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcbcf250",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"resources/logistic_reg_team1.pkl\"\n",
    "\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(logistic_reg,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364a98cd",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3292166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MultinomialNB object\n",
    "clf_multiNB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "301dd74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "nb_model = clf_multiNB.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e0bb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the NB model\n",
    "model_save_path = \"resources/NB_team1.pkl\"\n",
    "\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(nb_model,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472aceaf",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8f1edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest classifier object\n",
    "clf_RF = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b645dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "RF_model = clf_RF.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b83cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the RF model\n",
    "model_save_path = \"resources/RF_team1.pkl\"\n",
    "\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(RF_model,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model and motivate why it is the best choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff741c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss chosen methods logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae9db3",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3680ae2",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8e91f",
   "metadata": {},
   "source": [
    "[Tweet-Preprocessor](https://pypi.org/project/tweet-preprocessor/#description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed63101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
